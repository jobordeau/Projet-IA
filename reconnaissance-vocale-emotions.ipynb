{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import glob\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction des caractéristiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_name, **args):\n",
    "    \"\"\"\n",
    "   Extraction des caractéristiques d'un fichier audio .wav :\n",
    "            - MFCC (mfcc)\n",
    "            - Chroma (chroma)\n",
    "            - MEL Spectrogram Frequency (mel)\n",
    "            - Contrast (contrast)\n",
    "            - Tonnetz (tonnetz)\n",
    "        Usage :\n",
    "        features = extract_features(file, mel=True, mfcc=True)\n",
    "    \"\"\"\n",
    "    mfcc = args.get(\"mfcc\")\n",
    "    chroma = args.get(\"chroma\")\n",
    "    mel = args.get(\"mel\")\n",
    "    contrast = args.get(\"contrast\")\n",
    "    tonnetz = args.get(\"tonnetz\")\n",
    "    \n",
    "    \"\"\"\n",
    "    Chargement d'un fichier audio\n",
    "        X = Amplitude du son\n",
    "        sample_rate -> Fréquence de l'audio\n",
    "        sr -> La fréquence audio souhaité (None = Fréquence native de l’audio) \n",
    "        mono -> Si on veut un audio encodé en mono\n",
    "    \"\"\"\n",
    "    X, sample_rate = librosa.load(file_name, sr=16000, mono=True) \n",
    "        \n",
    "    if chroma or contrast:\n",
    "        stft = np.abs(librosa.stft(X))\n",
    "    result = np.array([])\n",
    "    if mfcc:\n",
    "        # mfccs recoit plusieur moyenne de mfcc qui sont transposé en colonne\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "        #hstack permet de concaténer deux tableaux à la suite en ligne \n",
    "        result = np.hstack((result, mfccs))\n",
    "    if chroma:\n",
    "        chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "        result = np.hstack((result, chroma))\n",
    "    if mel:\n",
    "        mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "        result = np.hstack((result, mel))\n",
    "    if contrast:\n",
    "        contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "        result = np.hstack((result, contrast))\n",
    "    if tonnetz:\n",
    "        tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "        result = np.hstack((result, tonnetz))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des datasets utilisés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour chaque dataset on a dictionnaire permettant d'obtenir l'émotion à partir du code utilisé :\n",
    "\n",
    "ravdessToEmotion = {\n",
    "    \"01\": \"neutral\",\n",
    "    \"02\": \"calm\", # Spécifique à ce dataset\n",
    "    \"03\": \"happy\",\n",
    "    \"04\": \"sad\",\n",
    "    \"05\": \"angry\",\n",
    "    \"06\": \"fearful\",\n",
    "    \"07\": \"disgust\",\n",
    "    \"08\": \"surprised\"\n",
    "}\n",
    "\n",
    "emodbToEmotion = {\n",
    "    \"N\": \"neutral\",   \n",
    "    \"F\": \"happy\",\n",
    "    \"T\": \"sad\",\n",
    "    \"W\": \"angry\",\n",
    "    \"A\": \"fearful\",\n",
    "    \"E\": \"disgust\",\n",
    "    \"L\": \"boredom\" # Spécifique à ce dataset\n",
    "}\n",
    "\n",
    "tessToEmotion = {\n",
    "    \"neutral\": \"neutral\",   \n",
    "    \"happy\": \"happy\",\n",
    "    \"sad\": \"sad\",\n",
    "    \"angry\": \"angry\",\n",
    "    \"fear\": \"fearful\",\n",
    "    \"disgust\": \"disgust\",\n",
    "    \"ps\": \"surprised\" # En réalité \"pleasent surprise\"=agréable surprise\n",
    "}\n",
    "\n",
    "saveeToEmotion = {\n",
    "    'n': \"neutral\",\n",
    "    'h': \"happy\",\n",
    "    'sa': \"sad\",\n",
    "    'a': \"angry\", \n",
    "    'f': \"fearful\",\n",
    "    'd': \"disgust\",\n",
    "    'su': \"surprised\"\n",
    "}\n",
    "\n",
    "cremadToEmotion = {\n",
    "    \"NEU\": \"neutral\",\n",
    "    \"HAP\": \"happy\",\n",
    "    \"SAD\": \"sad\",\n",
    "    \"ANG\":\"angry\",\n",
    "    \"FEA\": \"fearful\",\n",
    "    \"DIS\": \"disgust\",\n",
    "    \n",
    "}\n",
    "\n",
    "SELECTION_EMOTIONS = { # Dictionnaire des émotions auxquelles ont s'intéresse\n",
    "    \"neutral\",\n",
    "    \"sad\",\n",
    "    \"happy\",\n",
    "    \"angry\"\n",
    "}\n",
    "\n",
    "SELECTION_DATASETS = { # Dictionnaire des datasets à utiliser\n",
    "    #\"cremad\",\n",
    "    #\"emodb\",\n",
    "    \"ravdess\",\n",
    "    \"tess\",\n",
    "    \"savee\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Fonctions utilisées pour connaître l'émotion correspondante au fichier, selon le dataset:\n",
    "def ravdessConverter(name):\n",
    "    return ravdessToEmotion[name.split(\"-\")[2]]\n",
    "            \n",
    "def emodbConverter(name):\n",
    "    return emodbToEmotion[name[5]]\n",
    "\n",
    "def cremadConverter(name):\n",
    "    return cremadToEmotion[name.split(\"_\")[2]]\n",
    "\n",
    "def tessConverter(name):\n",
    "    return tessToEmotion[name.split(\"_\")[2].split(\".\")[0]]\n",
    "\n",
    "def saveeConverter(name):\n",
    "    return saveeToEmotion[re.sub('[0-9]|\\.wav','', name)]\n",
    "            \n",
    "\n",
    "def fileToEmotion(dataset, file):\n",
    "    \"\"\"\n",
    "    Extraction pour un dataset donné et un fichier donné de l'émotion correspondante\n",
    "    \"\"\"\n",
    "    switcher = { # Dictionnaire des fonctions à utiliser\n",
    "        \"ravdess\": ravdessConverter,\n",
    "        \"cremad\": cremadConverter,\n",
    "        \"emodb\": emodbConverter,\n",
    "        \"tess\": tessConverter,\n",
    "        \"savee\": saveeConverter\n",
    "    }\n",
    "    func = switcher.get(dataset, lambda: \"Dataset invalide\")\n",
    "    return func(file)\n",
    "       \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(test_size=0.25):    \n",
    "    \"\"\"\n",
    "    Chargement des données dans 2 listes :\n",
    "        - X contient les caractéristiques/features\n",
    "        - y contient l'émotion correspondante (pour les features au même index dans X)\n",
    "    Puis séparation en 4 ensembles:\n",
    "        - X_train et y_train pour l'entraînement d'un modèle\n",
    "        - X_test et y_test pour le test d'un modèle\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "               \n",
    "    for file in glob.glob(\"../data/**/*.wav\", recursive=True): # Parcours de l'arborescence des datasets\n",
    "        \n",
    "        basename = os.path.basename(file) # Obtention du nom du fichier\n",
    "        dataset = file.split(\"\\\\\")[1][5:]\n",
    "        \n",
    "        if dataset not in SELECTION_DATASETS: # On regarde si on utilise ce dataset\n",
    "            continue\n",
    "            \n",
    "        emotion = fileToEmotion(dataset, basename)\n",
    "        if emotion not in SELECTION_EMOTIONS: # On regarde si on s'intéresse à cette émotion\n",
    "            continue\n",
    "            \n",
    "        features = extract_features(file, mfcc=True, chroma=True, mel=True) # Extraction des caractéristiques\n",
    "        # Stockage du couple features/emotion\n",
    "        X.append(features)\n",
    "        y.append(emotion)\n",
    "\n",
    "        # Séparation des données pour l'entraînement et le test\n",
    "    return train_test_split(np.array(X), y, test_size=test_size, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Chargement des datasets et des émotions sélectionnés\n",
    "    - 75% des données pour l'entraînement\n",
    "    - 25% pour le test \n",
    "\"\"\"\n",
    "# Peut prendre plusieurs secondes/minutes selon la sélection de datasets/émotions \n",
    "X_train, X_test, y_train, y_test = load_data(test_size=0.25)\n",
    "\n",
    "\n",
    "# Affichage du nombre d'audios utilisés :\n",
    "\n",
    "print(\"[Pour l'entraînement] :\", X_train.shape[0], \"fichiers\")\n",
    "print(\"[Pour le test] :\", X_test.shape[0], \"fichiers\")\n",
    "\n",
    "print(\"[Pour chaque fichier audio] :\", X_train.shape[1], \"caractéristiques\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilisation de plusieurs modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Avec DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "Arbre_decision = DecisionTreeClassifier(random_state=0, max_depth=20)\n",
    "print('[*Entrainement du modèle*]')\n",
    "\n",
    "# Entraînement\n",
    "clf = Arbre_decision.fit(X_train, y_train)\n",
    "# Prédiction\n",
    "ypredit = clf.predict(X_test)\n",
    "# Calcul de la précision\n",
    "treeAccuracy = accuracy_score(y_true=y_test, y_pred=ypredit)\n",
    "\n",
    "print(\"Précision pour l'arbre de décision: {:.2f}%\".format(treeAccuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avec SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(gamma=0.001)\n",
    "print('[*Entrainement du modèle*]')\n",
    "\n",
    "#Entraînement\n",
    "clf.fit(X_train,y_train)\n",
    "# Prédiction\n",
    "ypredit = clf.predict(X_test)\n",
    "# Calcul de la précision\n",
    "SVMAccuracy = accuracy_score(y_true=y_test, y_pred=ypredit)\n",
    "\n",
    "print(\"Précision pour SVM: {:.2f}%\".format(SVMAccuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avec MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(max_iter=300)\n",
    "print('[*Entrainement du modèle*]')\n",
    "\n",
    "# Entraînement\n",
    "clf.fit(X_train, y_train)\n",
    "# Prédiction\n",
    "ypredit = clf.predict(X_test)\n",
    "# Calcul de la précision\n",
    "MLPaccuracy = accuracy_score(y_true=y_test, y_pred=ypredit)\n",
    "\n",
    "print(\"Précision pour MLPClassifier: {:.2f}%\".format(MLPaccuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
